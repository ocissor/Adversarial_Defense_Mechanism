{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoencoderTraining.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOWT3csy4SE9N9Hv8C14/7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ocissor/Adversarial_Defense_Mechanism/blob/master/AutoencoderTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3s2zzxmExvW"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms,datasets\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import PIL\r\n",
        "from PIL import Image\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "from tqdm import tqdm\r\n",
        "from torch.autograd import Function\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from numpy import linalg as LA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPBvV6XhFbga"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Ea1SC4FCWn"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O3sQdhZFCa7"
      },
      "source": [
        "class ConvAutoencoder(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(ConvAutoencoder, self).__init__()\r\n",
        "        ## encoder layers ##\r\n",
        "        # conv layer (depth from 3 --> 16), 3x3 kernels\r\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \r\n",
        "        # conv layer (depth from 16 --> 4), 3x3 kernels\r\n",
        "        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\r\n",
        "        # pooling layer to reduce x-y dims by two; kernel and stride of 2\r\n",
        "        self.pool = nn.MaxPool2d(2, 2)\r\n",
        "        \r\n",
        "        ## decoder layers ##\r\n",
        "        ## a kernel of 2 and a stride of 2 will increase the spatial dims by 2\r\n",
        "        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\r\n",
        "        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ## encode ##\r\n",
        "        # add hidden layers with relu activation function\r\n",
        "        # and maxpooling after\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = self.pool(x)\r\n",
        "        # add second hidden layer\r\n",
        "        x = F.relu(self.conv2(x))\r\n",
        "        x = self.pool(x)  # compressed representation\r\n",
        "        \r\n",
        "        ## decode ##\r\n",
        "        # add transpose conv layers, with relu activation function\r\n",
        "        x = F.relu(self.t_conv1(x))\r\n",
        "        # output layer (with sigmoid for scaling from 0 to 1)\r\n",
        "        x = F.sigmoid(self.t_conv2(x))\r\n",
        "                \r\n",
        "        return x\r\n",
        "\r\n",
        "# initialize the NN\r\n",
        "model = ConvAutoencoder()\r\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22z7rHWFCfb"
      },
      "source": [
        "transform = transforms.ToTensor()\r\n",
        "\r\n",
        "# load the training and test datasets\r\n",
        "train_data = datasets.CIFAR10(root='data', train=True,\r\n",
        "                                   download=True, transform=transform)\r\n",
        "test_data = datasets.CIFAR10(root='data', train=False,\r\n",
        "                                  download=True, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXlBDgEXFCiZ"
      },
      "source": [
        "# Create training and test dataloaders\r\n",
        "\r\n",
        "num_workers = 0\r\n",
        "# how many samples per batch to load\r\n",
        "batch_size = 20\r\n",
        "\r\n",
        "# prepare data loaders\r\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\r\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\r\n",
        "\r\n",
        "# specify the image classes\r\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\r\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRTxdV7hFClW"
      },
      "source": [
        "#Loss function\r\n",
        "criterion = nn.BCELoss()\r\n",
        "\r\n",
        "#Optimizer\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL6I7-n-FCoJ"
      },
      "source": [
        "#Epochs\r\n",
        "n_epochs = 100\r\n",
        "\r\n",
        "for epoch in range(1, n_epochs+1):\r\n",
        "    # monitor training loss\r\n",
        "    train_loss = 0.0\r\n",
        "\r\n",
        "    #Training\r\n",
        "    for data in train_loader:\r\n",
        "        images, _ = data\r\n",
        "        images = images.to(device)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        outputs = model(images)\r\n",
        "        loss = criterion(outputs, images)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        train_loss += loss.item()*images.size(0)\r\n",
        "          \r\n",
        "    train_loss = train_loss/len(train_loader)\r\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myeD4-YKFCre"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/MyDrive/AutoencoderCifar10.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}